{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brandonmoss124/mgmt467-analytics-portfolio/blob/main/Lab8_Streaming_Pipeline_(3).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "bd5d907c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "bd5d907c",
        "outputId": "4923f4a4-4391-4f83-cac2-83c64655e7b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/321.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.3/321.3 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.4/41.4 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Setup: install Pub/Sub client library in Colab\n",
        "!pip install -q google-cloud-pubsub functions-framework\n",
        "\n",
        "from google.colab import auth  # comment out if not using Colab\n",
        "auth.authenticate_user()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33f5c779",
      "metadata": {
        "id": "33f5c779"
      },
      "source": [
        "# Lab 8: Building a Streaming Pipeline (Pub/Sub + Dataflow)\n",
        "\n",
        "This notebook documents your steps to convert the batch pipeline from Lab 7\n",
        "into a streaming pipeline using Pub/Sub and a Dataflow template.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d5beded",
      "metadata": {
        "id": "0d5beded"
      },
      "source": [
        "## 1. Pub/Sub Topic Setup\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ec8b3dd",
      "metadata": {
        "id": "7ec8b3dd"
      },
      "source": [
        "## 2. Modify Cloud Function to Publish to Pub/Sub\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "47a150ee",
      "metadata": {
        "id": "47a150ee"
      },
      "outputs": [],
      "source": [
        "from google.cloud import pubsub_v1\n",
        "import json\n",
        "import os\n",
        "import logging\n",
        "import functions_framework\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# TODO: update this to your actual project ID and topic name\n",
        "PROJECT_ID = os.environ.get(\"GOOGLE_CLOUD_PROJECT\", \"proven-agility-477721-q9\")\n",
        "TOPIC_ID = \"live-data-stream\"\n",
        "\n",
        "publisher = pubsub_v1.PublisherClient()\n",
        "TOPIC_PATH = publisher.topic_path(PROJECT_ID, TOPIC_ID)\n",
        "\n",
        "def publish_weather(weather_dict):\n",
        "    \"\"\"Publish a weather dict as JSON to Pub/Sub.\"\"\"\n",
        "    data_str = json.dumps(weather_dict)\n",
        "    future = publisher.publish(TOPIC_PATH, data=data_str.encode(\"utf-8\"))\n",
        "    message_id = future.result()\n",
        "    logger.info(f\"Published message ID: {message_id}\")\n",
        "\n",
        "@functions_framework.http\n",
        "def ingest_weather_producer(request):\n",
        "    \"\"\"HTTP Cloud Function that fetches weather and publishes to Pub/Sub.\n",
        "\n",
        "    NOTE: This expects you to have defined `fetch_weather_lafayette()`\n",
        "    (from Lab 7) in the same source file.\n",
        "    \"\"\"\n",
        "    weather_json = fetch_weather_lafayette()\n",
        "    publish_weather(weather_json)\n",
        "    return (\"OK: message published\", 200)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aab62bd0",
      "metadata": {
        "id": "aab62bd0"
      },
      "source": [
        "## 3. Validate Streaming Data in BigQuery\n",
        "\n",
        "```sql\n",
        "SELECT *\n",
        "FROM `your-project.superstore_data.realtime_weather_streaming`\n",
        "ORDER BY dt_utc DESC\n",
        "LIMIT 10;\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc79a560",
      "metadata": {
        "id": "cc79a560"
      },
      "source": [
        "4. Challenge: Apache Beam Concepts Prompt\n",
        "\n",
        "My Prompt to Gemini:\n",
        "\n",
        "\"Explain Apache Beam's three core concepts Pipeline, PCollection, and ParDo using an assembly line or factory analogy.\"\n",
        "\n",
        "Gemini’s Response:\n",
        "\n",
        "Think of Apache Beam like a factory assembly line:\n",
        "\n",
        "- **Pipeline** is the entire assembly line in the factory. It defines the overall path that items (data) will follow from start to finish.\n",
        "- **PCollection** is the set of items moving along the conveyor belt — the data flowing through the pipeline.\n",
        "- **ParDo** is like a worker or robot at a specific station on the line that performs an operation on each item (for example, cleaning, painting, or inspecting each product).\n",
        "\n",
        "Together, the Pipeline (line), PCollection (items), and ParDo (workers) describe how data is created, transformed, and passed along in a streaming or batch system.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}