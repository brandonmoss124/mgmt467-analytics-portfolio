{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brandonmoss124/mgmt467-analytics-portfolio/blob/main/Lab5_Classification_BQML_confident_nexus_475419_k9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0d3a978",
      "metadata": {
        "id": "d0d3a978"
      },
      "source": [
        "\n",
        "# Lab 5 — Predicting Diversions (Classification with **BQML**)\n",
        "\n",
        "**Objective:** Train and evaluate a **logistic regression** model in **BigQuery ML** to classify whether a flight will be **diverted** (TRUE/FALSE).  \n",
        "**Business context:** Proactively flag likely diversions to manage logistics and passenger communication.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4749d919",
      "metadata": {
        "id": "4749d919"
      },
      "source": [
        "## 1) Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "827bdcd0",
      "metadata": {
        "id": "827bdcd0"
      },
      "outputs": [],
      "source": [
        "\n",
        "# If running in Colab:\n",
        "# from google.colab import auth\n",
        "# auth.authenticate_user()\n",
        "\n",
        "!pip -q install -U google-cloud-bigquery pandas-gbq google-cloud-bigquery-storage\n",
        "\n",
        "from google.cloud import bigquery\n",
        "import pandas as pd\n",
        "\n",
        "print(\"BigQuery libraries installed.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8dbb6823",
      "metadata": {
        "id": "8dbb6823"
      },
      "source": [
        "## 2) Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7345da4",
      "metadata": {
        "id": "e7345da4"
      },
      "outputs": [],
      "source": [
        "\n",
        "# >>> EDIT THESE <<<\n",
        "PROJECT_ID = \"confident-nexus-475419-k9\"\n",
        "DATASET_ID = \"superstore_data\"     # Use an existing dataset or create one\n",
        "LOCATION   = \"US\"                  # Match your dataset location\n",
        "MODEL_ID   = \"flight_diversion_classifier\"\n",
        "\n",
        "MODEL_FQN = f\"`{PROJECT_ID}.{DATASET_ID}.{MODEL_ID}`\"\n",
        "\n",
        "client = bigquery.Client(project=PROJECT_ID, location=LOCATION)\n",
        "\n",
        "print(\"Project:\", PROJECT_ID)\n",
        "print(\"Dataset:\", DATASET_ID)\n",
        "print(\"Model:\", MODEL_FQN)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7230a81a",
      "metadata": {
        "id": "7230a81a"
      },
      "source": [
        "\n",
        "## 3) Business Question & Trade-offs\n",
        "\n",
        "**Question:** Which is more costly for the airline — a **false positive** (predicting a diversion that doesn’t happen) or a **false negative** (missing a diversion that does happen)?\n",
        "\n",
        "**Answer (document your reasoning):**  \n",
        "*False negatives* usually cost more: if a real diversion isn’t predicted, the airline may have **no staff/equipment in place**, leading to **delays, missed connections, hotel/meal vouchers**, and reputational harm. *False positives* also have costs (unnecessary preparations/notifications), but they’re typically **less disruptive** than being surprised by an actual diversion.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cfd8ca8",
      "metadata": {
        "id": "6cfd8ca8"
      },
      "source": [
        "## 4) Train a Classification Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b0b53e3",
      "metadata": {
        "id": "3b0b53e3"
      },
      "outputs": [],
      "source": [
        "\n",
        "prompt = \"\"\"\n",
        "# TASK: Generate a BQML query to create a classification model.\n",
        "# GOAL: Predict the 'diverted' column using 'distance', 'carrier', and 'dep_delay' as features.\n",
        "# SPECIFICATIONS: The model type must be 'LOGISTIC_REG'.\n",
        "\"\"\"\n",
        "print(prompt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a31db9e",
      "metadata": {
        "id": "9a31db9e"
      },
      "outputs": [],
      "source": [
        "\n",
        "create_model_sql = f\"\"\"\n",
        "CREATE OR REPLACE MODEL {MODEL_FQN}\n",
        "OPTIONS(\n",
        "  model_type='LOGISTIC_REG',\n",
        "  input_label_cols=['diverted_label'],\n",
        "  enable_global_explain=TRUE\n",
        ") AS\n",
        "SELECT\n",
        "  CAST(diverted AS BOOL) AS diverted_label,\n",
        "  distance,\n",
        "  carrier,\n",
        "  dep_delay\n",
        "FROM `bigquery-public-data.airline_ontime_data.flights`\n",
        "WHERE diverted IS NOT NULL\n",
        "  AND distance IS NOT NULL\n",
        "  AND dep_delay IS NOT NULL\n",
        "LIMIT 300000\n",
        "\"\"\"\n",
        "print(create_model_sql)\n",
        "job = client.query(create_model_sql)\n",
        "job.result()\n",
        "print(\"Model created:\", job.job_id)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1621fef",
      "metadata": {
        "id": "a1621fef"
      },
      "source": [
        "## 5) Evaluate with ML.EVALUATE (+ Confusion Matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c3ef4ea",
      "metadata": {
        "id": "5c3ef4ea"
      },
      "outputs": [],
      "source": [
        "\n",
        "evaluate_sql = f\"\"\"\n",
        "SELECT *\n",
        "FROM ML.EVALUATE(MODEL {MODEL_FQN})\n",
        "\"\"\"\n",
        "print(evaluate_sql)\n",
        "eval_df = client.query(evaluate_sql).result().to_dataframe()\n",
        "eval_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65b8e4d5",
      "metadata": {
        "id": "65b8e4d5"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Confusion matrix at default threshold 0.5\n",
        "cm_05_sql = f\"\"\"\n",
        "SELECT *\n",
        "FROM ML.CONFUSION_MATRIX(MODEL {MODEL_FQN}, STRUCT(0.5 AS threshold))\n",
        "\"\"\"\n",
        "print(cm_05_sql)\n",
        "cm_05 = client.query(cm_05_sql).result().to_dataframe()\n",
        "cm_05\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8436c942",
      "metadata": {
        "id": "8436c942"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Confusion matrix at threshold 0.75\n",
        "cm_075_sql = f\"\"\"\n",
        "SELECT *\n",
        "FROM ML.CONFUSION_MATRIX(MODEL {MODEL_FQN}, STRUCT(0.75 AS threshold))\n",
        "\"\"\"\n",
        "print(cm_075_sql)\n",
        "cm_075 = client.query(cm_075_sql).result().to_dataframe()\n",
        "cm_075\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b7ce997",
      "metadata": {
        "id": "9b7ce997"
      },
      "source": [
        "### Explainer Prompt (Confusion Matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32104a89",
      "metadata": {
        "id": "32104a89"
      },
      "outputs": [],
      "source": [
        "\n",
        "prompt = \"\"\"\n",
        "# TASK: Explain a confusion matrix in a specific business context.\n",
        "# CONTEXT: I'm predicting flight diversions. My confusion matrix from ML.EVALUATE shows (example) 10 true positives, 50 false positives, 5 false negatives, and 10000 true negatives.\n",
        "# GOAL: Explain what 'false positives' and 'false negatives' represent in plain English for an airline operations manager. Based on my numbers, what is my model good at, and where is it weak?\n",
        "\"\"\"\n",
        "print(prompt)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc1cc9ec",
      "metadata": {
        "id": "fc1cc9ec"
      },
      "source": [
        "\n",
        "**Example interpretation:**  \n",
        "- **False positives** = we prepped for a diversion that didn’t happen (extra cost, but manageable).  \n",
        "- **False negatives** = a diversion occurred without warning (high disruption).  \n",
        "If false negatives are low and true negatives are very high, the model is **good at identifying non-diversions**; if false positives are elevated, it tends to **over-warn**, which may be acceptable if the business prioritizes avoiding surprise diversions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1399367",
      "metadata": {
        "id": "c1399367"
      },
      "source": [
        "## 6) Challenge — Custom Threshold with ML.PREDICT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "294a1fe4",
      "metadata": {
        "id": "294a1fe4"
      },
      "outputs": [],
      "source": [
        "\n",
        "challenge_prompt = \"\"\"\n",
        "# TASK: Help me write an ML.PREDICT query in BigQuery ML that uses a custom threshold of 0.75.\n",
        "# CONTEXT: I'm predicting 'diverted' using a logistic regression model.\n",
        "# GOAL: Return predicted_label and predicted_probability with threshold=0.75, and explain why an airline might choose a higher threshold for predicting diversions.\n",
        "\"\"\"\n",
        "print(challenge_prompt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2dd6c3b8",
      "metadata": {
        "id": "2dd6c3b8"
      },
      "outputs": [],
      "source": [
        "\n",
        "predict_075_sql = f\"\"\"\n",
        "SELECT *\n",
        "FROM ML.PREDICT(\n",
        "  MODEL {MODEL_FQN},\n",
        "  (\n",
        "    SELECT distance, carrier, dep_delay\n",
        "    FROM `bigquery-public-data.airline_ontime_data.flights`\n",
        "    WHERE diverted IS NOT NULL AND distance IS NOT NULL AND dep_delay IS NOT NULL\n",
        "    LIMIT 1000\n",
        "  ),\n",
        "  STRUCT(0.75 AS threshold)\n",
        ")\n",
        "\"\"\"\n",
        "print(predict_075_sql)\n",
        "pred_df = client.query(predict_075_sql).result().to_dataframe()\n",
        "pred_df.head()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}